{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import paho.mqtt.client as mqtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "#from tf_trt_models.detection import download_detection_model, build_detection_graph\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-03 13:30:38--  https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb?raw=true\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/yeephycho/tensorflow-face-detection/raw/master/model/frozen_inference_graph_face.pb [following]\n",
      "--2020-06-03 13:30:38--  https://github.com/yeephycho/tensorflow-face-detection/raw/master/model/frozen_inference_graph_face.pb\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/yeephycho/tensorflow-face-detection/master/model/frozen_inference_graph_face.pb [following]\n",
      "--2020-06-03 13:30:38--  https://raw.githubusercontent.com/yeephycho/tensorflow-face-detection/master/model/frozen_inference_graph_face.pb\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.188.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.188.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22684355 (22M) [application/octet-stream]\n",
      "Saving to: ‘data/frozen_inference_graph_face.pb’\n",
      "\n",
      "data/frozen_inferen 100%[===================>]  21.63M  9.53MB/s    in 2.3s    \n",
      "\n",
      "2020-06-03 13:30:44 (9.53 MB/s) - ‘data/frozen_inference_graph_face.pb’ saved [22684355/22684355]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/yeephycho/tensorflow-face-detection\n",
    "FROZEN_GRAPH_NAME = 'data/frozen_inference_graph_face.pb'\n",
    "!wget https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb?raw=true -O {FROZEN_GRAPH_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=''\n",
    "frozen_graph = tf.compat.v1.GraphDef()\n",
    "with open(os.path.join(output_dir, FROZEN_GRAPH_NAME), 'rb') as f:\n",
    "  frozen_graph.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few magical constants..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/NVIDIA-AI-IOT/tf_trt_models/blob/master/tf_trt_models/detection.py\n",
    "INPUT_NAME='image_tensor'\n",
    "BOXES_NAME='detection_boxes'\n",
    "CLASSES_NAME='detection_classes'\n",
    "SCORES_NAME='detection_scores'\n",
    "MASKS_NAME='detection_masks'\n",
    "NUM_DETECTIONS_NAME='num_detections'\n",
    "\n",
    "input_names = [INPUT_NAME]\n",
    "output_names = [BOXES_NAME, CLASSES_NAME, SCORES_NAME, NUM_DETECTIONS_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a session and load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.compat.v1.Session(config=tf_config)\n",
    "\n",
    "# use this if you want to try on the optimized TensorRT graph\n",
    "# Note that this will take a while\n",
    "# tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "# use this if you want to try directly on the frozen TF graph\n",
    "# this is much faster\n",
    "tf.import_graph_def(frozen_graph, name='')\n",
    "\n",
    "tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\n",
    "tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\n",
    "tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\n",
    "tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\n",
    "tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress boxes that are below the threshold.. \n",
    "DETECTION_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to capture faces: preprocess the image, run network on the image, crop the image to contain only the face, then send the face to message broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_faces(image):\n",
    "    \n",
    "    image_resized = cv.resize(image, (300,300), interpolation = cv.INTER_AREA)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={\n",
    "        tf_input: image_resized[None, ...]\n",
    "    })\n",
    "\n",
    "    boxes = boxes[0] # index by 0 to remove batch dimension\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "    num_detections = num_detections[0]\n",
    "    \n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # plot boxes exceeding score threshold\n",
    "    for i in range(int(num_detections)):\n",
    "        if scores[i] < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "        # scale box to image coordinates\n",
    "        box = boxes[i] * np.array([image.shape[0], image.shape[1], image.shape[0], image.shape[1]])\n",
    "\n",
    "        # display rectangle\n",
    "        #patch = patches.Rectangle((box[1], box[0]), box[3] - box[1], box[2] - box[0], color='g', alpha=0.3)\n",
    "        #ax.add_patch(patch)\n",
    "\n",
    "        # display class index and score\n",
    "        #plt.text(x=box[1] + 10, y=box[2] - 10, s='%d (%0.2f) ' % (classes[i], scores[i]), color='w')\n",
    "        \n",
    "        # capture the face\n",
    "        face = image[int(box[0]):int(box[2]),int(box[1]):int(box[3])]\n",
    "        #ax.imshow(face)\n",
    "        \n",
    "        rc, jpg=cv.imencode('.png', face)\n",
    "        msg = jpg.tobytes()\n",
    "        \n",
    "        client.publish(\"faces_detected\", payload=msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture faces for a fixed number of times to calculate the FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  8\n"
     ]
    }
   ],
   "source": [
    "# create a new client instance and connect to the local broker.\n",
    "client = mqtt.Client()\n",
    "client.connect(\"172.18.0.2\")\n",
    "\n",
    "cap = cv.VideoCapture(1)    \n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(50):\n",
    "    ret, frame = cap.read()\n",
    "    frame_fix = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    capture_faces(frame_fix)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"FPS: \", int(50/(t1-t0)))\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captue faces for cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new client instance and connect to the local broker.\n",
    "client = mqtt.Client()\n",
    "client.connect(\"172.18.0.2\")\n",
    "\n",
    "cap = cv.VideoCapture(1)    \n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame_fix = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    capture_faces(frame_fix)\n",
    "    cv.waitKey(1)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close session to release resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
